{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a99fd1-f3f7-4c39-baea-36580e635f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from nomad_utility_workflows.utils.entries import download_entry_by_id\n",
    "from nomad_utility_workflows.utils.uploads import (\n",
    "    upload_files_to_nomad,\n",
    "    get_upload_by_id,\n",
    "    edit_upload_metadata,\n",
    "    publish_upload\n",
    ")\n",
    "from nomad_utility_workflows.utils.entries import get_entries_of_upload\n",
    "from nomad_utility_workflows.utils.datasets import create_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4057b-177a-4abd-be78-cd8125899389",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = ['0iCl0nWwCftF0tgQOaklcQLFB68E', '24Q4MoaAUtsWN7Hepw3UH3TU93pX', '6V_q8X39he-dakYHifH_3Z53GTdZ']\n",
    "responses = []\n",
    "for i_entry, entry in enumerate(entries):\n",
    "    folder_nm = f'DFT-{i_entry+1}'\n",
    "    os.makedirs(f'{folder_nm}', exist_ok=True)\n",
    "    responses.append(download_entry_by_id(entry, url='prod', zip_file_name=os.path.join(folder_nm, f'{entry}.zip')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a4c5df-20af-4f02-8c3e-a7356fe92fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_upload_ids = []\n",
    "responses = []\n",
    "\n",
    "# define the timing parameters\n",
    "max_wait_time = 60  # 60 seconds\n",
    "interval = 5  # 5 seconds\n",
    "\n",
    "for i_entry, entry in enumerate(entries):\n",
    "    fnm = os.path.join(os.getcwd(), f'DFT-{i_entry+1}' ,f'{entry}.zip')\n",
    "    # make the upload\n",
    "    upload_id = upload_files_to_nomad(filename=fnm, url='test')\n",
    "    dft_upload_ids.append(upload_id)\n",
    "\n",
    "    # wait until the upload is processed successfully before continuing\n",
    "    elapsed_time = 0\n",
    "    while elapsed_time < max_wait_time:\n",
    "        nomad_upload = get_upload_by_id(upload_id, url='test')\n",
    "\n",
    "        # Check if the upload is complete\n",
    "        if nomad_upload.process_status == 'SUCCESS':\n",
    "            responses.append(nomad_upload)\n",
    "            break\n",
    "\n",
    "        # Wait the specified interval before the next call\n",
    "        time.sleep(interval)\n",
    "        elapsed_time += interval\n",
    "    else:\n",
    "        raise TimeoutError(f'Maximum wait time of {max_wait_time/60.} minutes exceeded. Upload with id {upload_id} is not complete.')\n",
    "\n",
    "    print(dft_upload_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c2143-8a16-4eec-ba58-44b78e3952f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_entry_ids = []\n",
    "for upload in dft_upload_ids:\n",
    "    entries = get_entries_of_upload(upload, url='test', with_authentication=True)\n",
    "    assert len(entries) == 1\n",
    "    dft_entry_ids.append(entries[0].entry_id)\n",
    "print(dft_entry_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b06f7b-46a1-419f-97d0-5ee721c44cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = create_dataset('Example Dataset - DPG Tutorial 2025 - <your name>', url='test')\n",
    "print(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed3f70-ce3a-4390-97a7-16deaa282483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft_upload_ids - should be previously defined in your notebook\n",
    "# dataset_id - should be previously defined in your notebook\n",
    "responses = []\n",
    "\n",
    "# define the timing parameters\n",
    "max_wait_time = 30  # 30 seconds\n",
    "interval = 5  # 5 seconds\n",
    "\n",
    "for i_upload, upload in enumerate(dft_upload_ids):\n",
    "    metadata_new = {'upload_name': f'Test Upload - DFT-{i_upload}', 'datasets': dataset_id}\n",
    "    _ = edit_upload_metadata(upload, url='test', upload_metadata=metadata_new)\n",
    "\n",
    "    # wait until the upload is processed successfully before continuing\n",
    "    elapsed_time = 0\n",
    "    while elapsed_time < max_wait_time:\n",
    "        nomad_upload = get_upload_by_id(upload, url='test')\n",
    "\n",
    "        # Check if the edit upload is complete\n",
    "        if nomad_upload.process_status == 'SUCCESS':\n",
    "            responses.append(nomad_upload)\n",
    "            break\n",
    "\n",
    "        # Wait the specified interval before the next call\n",
    "        time.sleep(interval)\n",
    "        elapsed_time += interval\n",
    "    else:\n",
    "        raise TimeoutError(f'Maximum wait time of {max_wait_time/60.} minutes exceeded. Edit Upload with id {upload} is not complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718e81f-1c3b-4954-b126-8a12ec75af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure to spin up this notebook in the same folder as the PIDs.json file\n",
    "with open(os.path.join('<path to PIDs>', 'PIDs.json')) as f:\n",
    "    pids_dict = json.load(f)\n",
    "md_upload_id = pids_dict.get('upload_ids').get('md-workflow') # '4Fvz-xp8Rq-fB5t3_WxDhg'\n",
    "metadata_new = {'upload_name': f'Test Upload - MD-equilibration', 'datasets': dataset_id}\n",
    "_ = edit_upload_metadata(md_upload_id, url='test', upload_metadata=metadata_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fe777-a51d-4799-8d29-a9f161af3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomad_upload = get_upload_by_id(md_upload_id, url='test')\n",
    "\n",
    "print(nomad_upload.process_status == 'SUCCESS')\n",
    "print(nomad_upload.process_running is False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784429d-eed8-4805-a411-a48924dac3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_upload_ids = [*dft_upload_ids, md_upload_id]\n",
    "responses = []\n",
    "\n",
    "# define the timing parameters\n",
    "max_wait_time = 30  # 30 seconds\n",
    "interval = 5  # 5 seconds\n",
    "\n",
    "for upload in all_upload_ids:\n",
    "    published_upload = publish_upload(upload, url='test')\n",
    "\n",
    "    # wait until the upload is processed successfully before continuing\n",
    "    elapsed_time = 0\n",
    "    while elapsed_time < max_wait_time:\n",
    "        nomad_upload = get_upload_by_id(upload, url='test')\n",
    "\n",
    "        # Check if the edit upload is complete\n",
    "        if nomad_upload.process_status == 'SUCCESS':\n",
    "            responses.append(nomad_upload)\n",
    "            break\n",
    "\n",
    "        # Wait the specified interval before the next call\n",
    "        time.sleep(interval)\n",
    "        elapsed_time += interval\n",
    "    else:\n",
    "        raise TimeoutError(f'Maximum wait time of {max_wait_time/60.} minutes exceeded. Publish Upload with id {upload} is not complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71515a-4f45-42fa-8e05-581e9a46f4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DPG-tutorial",
   "language": "python",
   "name": "dpg-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
